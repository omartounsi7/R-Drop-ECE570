# Project Overview

This project explores the effects of R-Drop (Regularized Dropout) on different neural network architectures. The experiments can be run by accessing the final_implementation notebook, running the first cell which has all of the function implementations, setting the hyperparameters in the second cell and running it, and then running any of the last cells which conduct training of the models.
